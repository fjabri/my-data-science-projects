{"cells": [{"cell_type": "markdown", "metadata": {"editable": false}, "source": "---\n## Algorithmes de Classification Multiclasses\n---\n\n<center><img src=\"https://python.gel.ulaval.ca/media/sio-u009/mlprocess_3.png\" alt=\"Processus d'apprentissage automatique\" width=\"50%\"/></center>\n\nDans cet exemple nous allons \u00e9tendre les algorithmes vu dans le module pr\u00e9c\u00e9dent au probl\u00e8me multi-classe. En effet, il n'\u00e9tait possible que de s\u00e9parer entre deux classes possibles dans la d\u00e9finition pr\u00e9c\u00e9dente du probl\u00e8me, mais que faire lorsqu'on a 3 ou plus classes parmi lesquelles discriminer ? \n\nEssayons de regarder les donn\u00e9es de plusieurs types d'Iris (les fleurs):\n\n<img src=\"https://cdn-images-1.medium.com/max/1600/1*2uGt_aWJoBjqF2qTzRc2JQ.jpeg\" width=\"500\"/>\n"}, {"cell_type": "markdown", "metadata": {"editable": false}, "source": "D\u00e9finissons un ensemble de fonctions qui vont nous aider \u00e0 visualiser plus simplement les r\u00e9sultats des diff\u00e9rents classificateurs apr\u00e8s avoir import\u00e9 les diff\u00e9rents mod\u00e8les."}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "%matplotlib inline\n\n# Code source: Ga\u00ebl Varoquaux\n#              Andreas M\u00fcller\n# Modified for documentation by Jaques Grobler\n# Traduit et d\u00e9compos\u00e9 par Camille Besse\n# License: BSD 3 clause\nprint(__doc__)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nfrom matplotlib.colors import ListedColormap\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import make_moons, make_circles, make_classification\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF, Matern, RationalQuadratic, ExpSineSquared, DotProduct, ConstantKernel\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\nfg = (24,8)\ncm_points = ListedColormap(['#FF0000','#FFFFFF', '#00FF00','#000000', '#0000FF'])\ncm = 'jet_r'\nparams = {'figure.titlesize': 'xx-large',\n          'font.size': '12',\n          'text.color': 'k',\n          'figure.figsize': fg,\n         }\npylab.rcParams.update(params)\n\n"}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "def creationMesh(X):\n    \"\"\"\n    Cr\u00e9e un grille sur un espace bidimensionnel. Prends le min et le max de chaque dimension et calcule la grille avec une r\u00e9solution de 0.02. \n    X: un vecteur \u00e0 deux colonnes de donn\u00e9es. \n    \"\"\"\n    h = .02  # step size in the mesh\n    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                         np.arange(y_min, y_max, h))\n    return xx,yy\n\n\ndef plotClassifierOnData(name,clf,data,i=3,n=1,multi=False):\n    \"\"\"\n    Pour Afficher les r\u00e9cultat d'un classificateur sur un dataset\n    name : le titre du graphique\n    clf : le classificateur \u00e0 utiliser\n    data : les donn\u00e9es \u00e0 utiliser\n    i : Le i\u00e8me graphique sur n \u00e0 afficher (pour afficher 3 graphiques par ligne)\n    n : Le nombre total de graphiques \u00e0 afficher\n    multi: d\u00e9termine si on affiche juste la fronti\u00e8re de d\u00e9cision (true) ou \n           le score/proba de chaque point de l'espace car on ne peut afficher le score en multiclasse.\n    \"\"\"\n    \n    # Pr\u00e9paration rapide des donn\u00e9es : \n    # normalisation des donn\u00e9es \n    X, y = data\n    X = StandardScaler().fit_transform(X)\n    # S\u00e9paration des donn\u00e9es en TRAIN - TEST\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=rng_seed)\n    # Pour la visualisation des r\u00e9gions et calcul des bornes \n    xx,yy = creationMesh(X)\n\n    # creation du bon nombre de figures \u00e0 afficher (3 par lignes)\n    ax = plt.subplot(n/3,3,i)\n    \n    # entrainement du classificateur et calcul du score final (accuracy)\n    clf.fit(X_train, y_train)\n    score = clf.score(X_test, y_test)\n\n    # Pour afficher les fronti\u00e8res de d\u00e9cision on va choisir une color pour \n    # chacun des points x,y du mesh [x_min, x_max]x[y_min, y_max].\n\n    # Si on est en multiclasse (2 ou +) on affiche juste les fronti\u00e8res\n    if multi:\n         Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n    else:# sinon on peut afficher le gradient du score\n        if hasattr(clf, \"decision_function\"):\n            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n        else:\n            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n\n    # On affiche le mesh de d\u00e9cision\n    Z = Z.reshape(xx.shape)\n    test = ax.contourf(xx, yy, Z, 100, cmap=cm, alpha=.8)\n\n    #On affiche la l\u00e9gende\n    cbar = plt.colorbar(test)\n    cbar.ax.set_title('score')\n    \n    # On affiche les points d'entrainement\n    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_points,\n               edgecolors='k',s=100)\n    # Et les points de test\n    ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_points, \n               edgecolors='k',marker='X',s=100)\n\n    # on d\u00e9finit les limites des axes et autres gogosses\n    ax.set_xlim(xx.min(), xx.max())\n    ax.set_ylim(yy.min(), yy.max())\n    \n    ax.set_title(name,fontsize=22)\n    # dont le score en bas \u00e0 droite\n    ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n            size=15, horizontalalignment='right')\n\n\ndef plotClassifier(name, clf, datasets):\n    \"\"\"\n    Affiche pour un classificateur donn\u00e9, son r\u00e9sultat sur l'ensemble des datasets pr\u00e9alablement d\u00e9termin\u00e9s\n    name : le nom du classificateur \u00e0 afficher (titre du graphique)\n    clf : un classificateur de scikit-learn\n    datasets : une liste de datasets\n    \"\"\"\n    f = plt.figure(figsize=fg)\n    # Pour chacun des DataSet\n    for ds_cnt, ds in enumerate(datasets):\n        plotClassifierOnData(name, clf, ds,ds_cnt+1,3)\n\n    plt.tight_layout()\n    plt.show()"}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "import pandas as pd\nimport seaborn as sns\n\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn import metrics\nfrom sklearn.multiclass import OneVsRestClassifier,OneVsOneClassifier\nfrom sklearn.preprocessing import StandardScaler,LabelEncoder\n\n\nfrom sklearn.model_selection import train_test_split\n\n## Pour le g\u00e9n\u00e9rateur de nombre pseu-al\u00e9atoires et la reproductibilit\u00e9 des r\u00e9sultats\nrng_seed = 0 \n\n## D\u00e9finition du noyau RBF\nnoyauRBF = 1.0 * RBF(length_scale=1.0, length_scale_bounds=(1e-1, 10.0))\n\niris = sns.load_dataset(\"iris\")\n\ng = sns.pairplot(iris, hue='species', markers=['+','d','x'])\nplt.show()\niris.sample(10)"}, {"cell_type": "markdown", "metadata": {"editable": false}, "source": "### Rappel : S\u00e9parer les donn\u00e9es en deux : entrainement et test\n#### Avantages\n\n   - En s\u00e9parant les donn\u00e9es al\u00e9atoirement on ne teste pas sur les m\u00eames donn\u00e9es que celles entrain\u00e9es\n   - Cela garantit que nous n'utiliseront pas les m\u00eames observations dans les deux ensembles \n   - Cela g\u00e9n\u00e9ralise mieux les donn\u00e9es plus rapidement\n\n#### Inconv\u00e9nients\n   - Le score d'exactitude sur l'ensemble de test varie en fonction des donn\u00e9es qui y ont \u00e9t\u00e9 s\u00e9lectionn\u00e9es\n   - On peut mitiger ca en utilisant la validation crois\u00e9e\n\n#### Notes\n   - Le score d'exactitude  des mod\u00e8les d\u00e9pend des observations de l'ensemble de test, qui est d\u00e9termin\u00e9 par l'initilisation  du g\u00e9n\u00e9rateur pseudo-al\u00e9atoire.\n   - Plus la complexit\u00e9 du mod\u00e8le augmente, plus l'exactitude d'entrainement augmente\n   - Si un mod\u00e8le est trop complexe (overfitting) ou pas assez complexe (underfitting), l'exactitude d'entrainement est trop basse. \n"}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "X = iris.drop('species', axis=1)\ny = iris['species']\n\n# Vous pouvez affichier les informations du dataset\n# print(X.head())\n# print(X.shape)\n# print(y.head())\n# print(y.shape)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=rng_seed)"}, {"cell_type": "markdown", "metadata": {"editable": false}, "source": "Une fois s\u00e9par\u00e9s on peut valider quelle serait la meilleure valeur de $k$ dans un $k$-NN sur l'ensemble des donn\u00e9es d'entrainement."}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "# experimentons avec diff\u00e9rentes valeurs de k\nk_range = list(range(1,26))\nscores = []\nfor k in k_range:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train, y_train)\n    y_pred = knn.predict(X_test)\n    scores.append(metrics.accuracy_score(y_test, y_pred))\n    \nplt.plot(k_range, scores)\nplt.xlabel('Valeur de k')\nplt.ylabel('Exactitude')\nplt.title('Exactitude pour diff\u00e9rentes valeurs de k dans les k-NN')\nplt.show()"}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "\n#Choisir les caract\u00e9ristiques en entr\u00e9e: \nc0 = 'sepal_length'\nc1 = 'sepal_width'\nc2 = 'petal_length'\nc3 = 'petal_width'\n\nf1 = c0\nf2 = c1\n#  ----------------------\n\n# Param\u00e9trer les classificateurs\nclfs = [\n    KNeighborsClassifier(n_neighbors=3, weights='uniform', leaf_size=30),\n    LogisticRegression(random_state=rng_seed,max_iter=1000,penalty='l2',C=0.01,solver='liblinear'),\n    SVC(kernel='rbf', C=1,gamma=.2,max_iter=1000),\n    DecisionTreeClassifier(max_depth=6, random_state=rng_seed),\n    RandomForestClassifier(max_depth=6, n_estimators=15, max_features=2, random_state=rng_seed),\n    AdaBoostClassifier(n_estimators=15, learning_rate=0.5,random_state=rng_seed),\n    MLPClassifier(hidden_layer_sizes=(5,), activation='relu', alpha=0.01, max_iter=10000, random_state=rng_seed),\n    GaussianProcessClassifier(kernel=noyauRBF),\n    GradientBoostingClassifier(n_estimators=15, learning_rate=0.5, subsample=1, max_depth=2, random_state=rng_seed),\n]\n# Liste des noms associ\u00e9s\nclf_names = [\n    'k-NN','R\u00e9gression Logistique','SVM',\n    'Arbre de d\u00e9cision','For\u00eat al\u00e9atoire','AdaBoost',\n    'Perceptron','Processus Gaussien','Gradient Boosting'   \n]\n\n#  ----------------------\n\n# Cr\u00e9ation du dataset \nX = iris[[f1,f2]].values\n\n## Encodage des esp\u00e8ces en valeurs num\u00e9riques pour la coloration\nle = LabelEncoder()\nle.fit(iris.species.unique())\ny = le.transform(iris.species)\ndata_iris = [X,y]\n#  ----------------------\n\n# Affichage des fronti\u00e8res de d\u00e9cision pour nos neuf classificateurs \nf = plt.figure(figsize= (20,20))\n\n# Pour chacun des Classificateurs\nfor cnt, clf in enumerate(clfs):\n    plotClassifierOnData(clf_names[cnt], OneVsRestClassifier(clf), data_iris,cnt+1,len(clfs),True)\n\n\nplt.tight_layout()\nplt.show()"}, {"cell_type": "markdown", "metadata": {"editable": false}, "source": "Voyons les matrices de confusion pour ces classificateurs : "}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "import itertools\nfrom sklearn.metrics import confusion_matrix, plot_confusion_matrix\n\ndef plot_confusion_matrix(clf,classes,                       \n                          title,i,n,X_train,y_train,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    Cette fonction calcule et affiche la matrice de confusion pour un classificateur donn\u00e9.\n    clf : classificateur\n    classes : les classes \u00e0 d\u00e9terminer dans le dataset\n    title : \n    \"\"\"\n    y_pred = clf.fit(X_train, y_train).predict(X_test)\n\n    # Calcul de la matrice de confusion\n    cnf_matrix = confusion_matrix(y_test, y_pred)\n    np.set_printoptions(precision=2)\n\n    cnf_matrix  = cnf_matrix .astype('float') / cnf_matrix.sum(axis=1)[:, np.newaxis]\n\n    ax = plt.subplot(n/3,3,i)\n    test = ax.imshow(cnf_matrix, interpolation='nearest', cmap=cmap)\n    ax.set_title(title)\n    cbar = plt.colorbar(test)\n\n    tick_marks = np.arange(len(classes))\n    ax.set_xticks(tick_marks)\n    ax.set_xticklabels(classes)\n    ax.set_yticks(tick_marks)\n    ax.set_yticklabels(classes)\n\n    thresh = cnf_matrix.max() / 2.\n    for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n        plt.text(j, i, format(cnf_matrix[i, j], '.2f'),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cnf_matrix[i, j] > thresh else \"black\",size=12)\n\n    \n    ax.set_ylabel('Vrai label')\n    ax.set_xlabel('label Pr\u00e9dit')\n\n\n# Affichage des matrices de confusion pour nos neuf classificateurs \nf = plt.figure(figsize= (20,20))\n\n# Pour chacun des Classificateurs\nfor cnt, clf in enumerate(clfs):\n    plot_confusion_matrix(OneVsRestClassifier(clf), iris.species.unique(), clf_names[cnt],cnt+1,len(clfs),X_train,y_train)\n\nplt.tight_layout()\nplt.show()"}, {"cell_type": "markdown", "metadata": {"editable": false}, "source": "___\n# Multiclasse : A vous de jouer ! \n___\n\nDans cet exercice vous avez les moyens de maintenant choisir le bon classificateur et ses hyperparam\u00e8tres en utilisant toutes les connaissances de la journ\u00e9e.\n\nNous allons charger un dataset contenant 4 types de fruits (Pommes, Oranges, Mandarines et Citrons) et c'est \u00e0 vous de d\u00e9terminer \u00e0 partir de leur masse, hauteur, largeur, couleur, quels sont les types de fruits.\n\nUn exemple de code vous est donn\u00e9 pour pouvoir visualiser les donn\u00e9es, mais rappelez vous qu'il est plus int\u00e9ressant d'utiliser l'ensemble des donn\u00e9es plutot que juste deux colonnes de celles-ci !\n"}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "# Importation du fichier de donn\u00e9es\nimport wget\n\n!rm './fruits.csv'\nwget.download('https://raw.githubusercontent.com/iid-ulaval/EEAA-datasets/master/fruits.csv','./fruits.csv')"}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "# On \u00e9limine la colonne \"subtype\" qui pourra faire l'objet d'exercieces suppl\u00e9mntaires\nfruits = pd.read_csv('fruits.csv', sep=',').drop('fruit_subtype',axis=1)"}, {"cell_type": "markdown", "metadata": {"editable": false}, "source": "Jetons un oeuil aux donn\u00e9es:\n\nTout d'abord les 10 premiers \u00e9l\u00e9ments."}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "fruits.sample(10)"}, {"cell_type": "markdown", "metadata": {"editable": false}, "source": "Puis, \u00e9tudions les relations qui existent entre chaque pair de carat\u00e9ristiques."}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "g = sns.pairplot(fruits.drop('fruit_label',axis=1), hue='fruit_name')\nplt.show()"}, {"cell_type": "markdown", "metadata": {"editable": false}, "source": "**Exercice :** Le code suivant montre l'apprentissage et la visualisation des r\u00e9sultats avec 2 caract\u00e9ristiques seulement. L'objectif \u00e9tant bien sur de trouver la meilleure combinaison algorithme/hyperparam\u00e8tres pour l'ensemble des caract\u00e9ristiques, \u00e0 vous d'adapter le code suivant :"}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "#Choisir les caract\u00e9ristiques en entr\u00e9e: \nc0 = 'mass'\nc1 = 'width'\nc2 = 'height'\nc3 = 'color_score'\n\n#  ----------------------\n\n# Cr\u00e9ation du dataset \nX = fruits[[c1,c3]].values\ny = fruits['fruit_label']\ndata = [X,y]\n#  ----------------------\n\n# Choix du classificateur\n\nchoix = 0\n\n# Choix des hyper-param\u00e8tres (grid search ? cross-validation ?)\nclfs = [\n    KNeighborsClassifier(n_neighbors=3, weights='uniform', leaf_size=30),\n    LogisticRegression(random_state=rng_seed,max_iter=1000,penalty='l2',C=0.01,solver='liblinear'),\n    SVC(kernel='rbf', C=1,gamma=.2,max_iter=1000),\n    DecisionTreeClassifier(max_depth=6, random_state=rng_seed),\n    RandomForestClassifier(max_depth=6, n_estimators=15, max_features=2, random_state=rng_seed),\n    AdaBoostClassifier(n_estimators=100, learning_rate=0.3,random_state=rng_seed),\n    MLPClassifier(hidden_layer_sizes=(5,), activation='relu', alpha=0.01, max_iter=1000, random_state=rng_seed),\n    GaussianProcessClassifier(kernel=noyauRBF),\n    GradientBoostingClassifier(n_estimators=15, learning_rate=0.5, subsample=1, max_depth=2, random_state=rng_seed),\n]\n\nclf_names = [\n    'k-NN','R\u00e9gression Logistique','SVM',\n    'Arbre de d\u00e9cision','For\u00eat al\u00e9atoire','AdaBoost',\n    'Perceptron','Processus Gaussien','Gradient Boosting'   \n]\n\n\n# Affichage des fronti\u00e8res de d\u00e9cision pour le classificateur choisi (OvO ? OvR ?)\nf = plt.figure(figsize= (15,5))\nplotClassifierOnData(clf_names[choix], OneVsOneClassifier(clfs[choix]), data,1,3,True)\nplt.tight_layout()\nplt.show()"}], "metadata": {"PAX": {"revision": 805, "userLang": "fr"}, "celltoolbar": "", "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.1"}, "revision": 805, "varInspector": {"cols": {"lenName": 16, "lenType": 16, "lenVar": 40}, "kernels_config": {"python": {"delete_cmd_postfix": "", "delete_cmd_prefix": "del ", "library": "var_list.py", "varRefreshCmd": "print(var_dic_list())"}, "r": {"delete_cmd_postfix": ") ", "delete_cmd_prefix": "rm(", "library": "var_list.r", "varRefreshCmd": "cat(var_dic_list()) "}}, "types_to_exclude": ["module", "function", "builtin_function_or_method", "instance", "_Feature"], "window_display": false}}, "nbformat": 4, "nbformat_minor": 2}