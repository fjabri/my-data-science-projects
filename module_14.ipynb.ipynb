{"cells": [{"cell_type": "markdown", "metadata": {"editable": false}, "source": "---\n# \u00c9valuation des mod\u00e8les de r\u00e9gression\n---\n\n<center><img src=\"https://python.gel.ulaval.ca/media/sio-u009/mlprocess_4.png\" alt=\"Processus d'apprentissage automatique\" width=\"50%\"/></center>\n\nDans cette s\u00e9quence nous allons \u00e9valuer, \u00e0 l'aide des diff\u00e9rentes m\u00e9triques vues dans le cours, diff\u00e9rents mod\u00e8les de r\u00e9gression.\n\nDans un premier temps nous allons repartir de l'exemple simple vu dans le module d'introduction (notre polyn\u00f4me de degr\u00e9 5) et \u00e9valuer trois mod\u00e8ls diff\u00e9rents. Dans un second temps nous allons \u00e9valuer le mod\u00e8le de votre choix sur un ensemble de donn\u00e9es public : Les donn\u00e9es des habitants de Californie.\n\nImportons d'abord les librairies n\u00e9cessaires.\n"}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "%matplotlib inline\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits import mplot3d\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import Ridge, LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.gaussian_process.kernels import RBF, WhiteKernel, ConstantKernel \nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.neural_network import MLPRegressor"}, {"cell_type": "markdown", "metadata": {"editable": false}, "source": "G\u00e9n\u00e9rons les donn\u00e9es sur notre polyn\u00f4me de degr\u00e9 5:"}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "X_lin = np.linspace(-10,10,100)[:,np.newaxis]\ndef generate_data(N):\n    x = np.random.uniform(-10,10,N)\n    y = np.polyval([0.03, 0.2, -1, -10, 100],x) + np.random.normal(0.0, 15.0, N)\n    return x.reshape(-1, 1), y"}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "X,y = generate_data(200)"}, {"cell_type": "markdown", "metadata": {"editable": false}, "source": "Et v\u00e9rifions les donn\u00e9es : "}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "fig, ax = plt.subplots()\nax.plot(X, y, 'o')\nax.plot(np.linspace(-10,10,100), np.polyval([0.03, 0.2, -1, -10, 100],np.linspace(-10,10,100)), color='black', linewidth=3)\nax.set_title('Data set')\nax.set_ylabel('y')\nax.set_xlabel('x')\nplt.show()"}, {"cell_type": "markdown", "metadata": {"editable": false}, "source": "## Pr\u00e9paration des donn\u00e9es train/validation/test 40% / 30% / 30%\n\nD\u00e9coupage du dataset en trois partie:"}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "X_, X_test, y_, y_test = train_test_split(X, y, test_size=0.30)\nX_train, X_val, y_train, y_val = train_test_split(X_, y_, test_size=0.428)"}, {"cell_type": "markdown", "metadata": {"editable": false}, "source": "## Calcul de l'erreur de Bayes sur validation\n\nVoici un exemple de calcul des m\u00e9triques $R^2$, erreur quadratique moyenne (MSE) et erreur absolue moyenne (MAE), si on avait le mod\u00e8le parfait (i.e la fonction originale). "}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "def f(x):\n    return np.polyval([0.03, 0.2, -1, -10, 100],x)\n\nR2 = r2_score(y_val, f(X_val))\nMSE = mean_squared_error(y_val, f(X_val))\nMAE = mean_absolute_error(y_val, f(X_val))\nprint('LR :', 'R2:', R2, 'MSE:', MSE, 'MAE:', MAE)"}, {"cell_type": "markdown", "metadata": {"editable": false}, "source": "On ne peut donc pas faire mieux que ca sur ces m\u00e9triques, cela nous donne une borne sup\u00e9rieure pour le $R^2$ et des bornes inf\u00e9rieures pour la MSE et la MAE."}, {"cell_type": "markdown", "metadata": {"editable": false}, "source": "## \u00c9valuation des m\u00e9triques de 3 mod\u00e8les sur validation\n\nEn utilisant une r\u00e9gression lin\u00e9aire ([`LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)) voyons la performance que l'on peut obtenir : \n\nEssayez de visualiser le mod\u00e8le r\u00e9sultat sur les donn\u00e9es initiales pour valider visuelement le r\u00e9sultat (profitons en quand on peut)."}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "#..."}, {"cell_type": "markdown", "metadata": {"editable": false}, "source": "En utilisant le noyau ci-dessous (dont vous pouvez adapter les hyperparam\u00e8tres), reproduisez l'exp\u00e9rience avec un mod\u00e8le de r\u00e9gression \u00e0 base de processus Gaussien ([`GaussianProcessRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html))"}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "kernel = 100.0 * RBF(length_scale=100.0, length_scale_bounds=(1e-2, 1e3)) \\\n               + WhiteKernel(noise_level=10, noise_level_bounds=(1e-10, 1e+3))\n\n#..."}, {"cell_type": "markdown", "metadata": {"editable": false}, "source": "Essayons enfin avec un perceptron multicouche ([`MLPRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html))"}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "# ... "}, {"cell_type": "markdown", "metadata": {"editable": false}, "source": "Essayez plusieurs hyperparam\u00e8tres et trouver le meilleur mod\u00e8le possible. Venez partager sur le forum le meilleur r\u00e9sultat que vous trouverez (en test ;-))"}, {"cell_type": "markdown", "metadata": {"editable": false}, "source": "# Exemple 1 avec donn\u00e9es r\u00e9elles : [california housing](https://developers.google.com/machine-learning/crash-course/california-housing-data-description)\n\nEssayons maintenant sur un ensemble de donn\u00e9es r\u00e9elles que vous avez probablement d\u00e9ja vu dans le module de pr\u00e9paration de donn\u00e9es. \n\nC'est l'ensemble de donn\u00e9es utilis\u00e9 dans le deuxi\u00e8me chapitre du livre d'Aur\u00e9lien G\u00e9ron \"Hands-On Machine learning with Scikit-Learn and TensorFlow\". Il constitue une excellente introduction \u00e0 la mise en \u0153uvre d'algorithmes d'apprentissage machine car il n\u00e9cessite un nettoyage rudimentaire des donn\u00e9es, comporte une liste de variables facilement compr\u00e9hensible et se situe \u00e0 une taille optimale entre \u00eatre trop ludique et trop encombrant.\n\nLes donn\u00e9es contiennent des informations provenant du recensement de 1990 en Californie. Ainsi, m\u00eame si elles ne vous aident pas \u00e0 pr\u00e9voir les prix actuels du logement, comme d'autres ensemble de donn\u00e9es plus r\u00e9cents, elles fournissent un ensemble de donn\u00e9es d'introduction accessible pour enseigner aux gens les bases de l'apprentissage machine.\n\nR\u00e9cup\u00e9rons les donn\u00e9es et s\u00e9parons les en trois sous ensembles (train-valid-test)\n\n"}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "from sklearn.datasets import fetch_california_housing\ndataset = fetch_california_housing()\ncal_X, cal_y = dataset.data, dataset.target\n\ncal_X_train, cal_X_test, cal_y_train, cal_y_test = train_test_split(cal_X, cal_y, test_size=0.30, random_state=42)"}, {"cell_type": "markdown", "metadata": {"editable": false}, "source": "### Entra\u00eenement et validation d'un r\u00e9gresseur sur california\n\nIci choisissons un regresseur (par exemple une r\u00e9gression [lin\u00e9aire](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html), un [SVR](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html) ou un [MLP](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html), mais vous pouvez choisir n'importe lequel [parmis tous ceux de SciKit-Learn](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning)) et \u00e9valuons les en validation crois\u00e9e (\u00e0 l'aide de la fonction [cross_val_score()]()). \n\nM'h\u00e9sitez pas \u00e0 aller sur le forum pour discuter de vos meilleurs mod\u00e8les et hyperparam\u00e8tres !"}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "# ..."}, {"cell_type": "markdown", "metadata": {"editable": false}, "source": "# Exemple 2 avec donn\u00e9es r\u00e9elles : [Diab\u00e8te LARS](https://web.stanford.edu/~hastie/Papers/LARS/)\n\nDans cet ensemble de donn\u00e9es, dix variables de base, l'\u00e2ge, le sexe, l'indice de masse corporelle, la pression art\u00e9rielle moyenne et six mesures de s\u00e9rum sanguin ont \u00e9t\u00e9 obtenues pour chacun des 44 patients diab\u00e9tiques, ainsi que la r\u00e9ponse d'int\u00e9r\u00eat, une mesure quantitative de la progression de la maladie un an apr\u00e8s la base."}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "from sklearn.datasets import load_diabetes\ndataset = load_diabetes()\ndia_X, dia_y = dataset.data, dataset.target\n\ndia_X_train, dia_X_test, dia_y_train, dia_y_test = train_test_split(dia_X, dia_y, test_size=0.30, random_state=42)"}, {"cell_type": "markdown", "metadata": {"editable": false}, "source": "### Entra\u00eenement et validation d'un r\u00e9gresseur sur diabetes\n\nIl s'agit de repratiquer encore l'exemple pr\u00e9c\u00e9dent avec un autre ensemble de donn\u00e9es et donc un autre \"meilleur\" mod\u00e8le.\n\nM'h\u00e9sitez pas \u00e0 aller sur le forum pour discuter de vos meilleurs mod\u00e8les et hyperparam\u00e8tres !"}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "# ..."}], "metadata": {"PAX": {"revision": 913, "userLang": "fr"}, "celltoolbar": "", "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.1"}, "revision": 913}, "nbformat": 4, "nbformat_minor": 2}