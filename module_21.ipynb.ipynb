{"cells": [{"cell_type": "markdown", "metadata": {"editable": false}, "source": "---\n# Tutoriel 3 - Classificateur CNN\n---\n\n<center><img src=\"https://python.gel.ulaval.ca/media/sio-u009/mlprocess_3.png\" alt=\"Processus d'apprentissage automatique\" width=\"50%\"/></center>\n\nDans ce tutoriel, nous allons designer un r\u00e9seau \u00e0 convolution pour faire de la classification d'images. Pour ce faire, nous utilisons le jeu de donn\u00e9es CIFAR10 qui est plus complexe que celui de MNIST."}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "%matplotlib inline\nimport matplotlib.pyplot as plt\nimport math\nimport torch\nimport numpy as np\nfrom torch import optim, nn\nfrom torchvision import transforms\nimport torchvision.models as models\nfrom torchvision.datasets.cifar import CIFAR10\nfrom torch.utils.data import DataLoader, random_split\nfrom torch.nn import functional as F\n\nfrom poutyne.framework import Model, ModelCheckpoint, Callback, CSVLogger, EarlyStopping, ReduceLROnPlateau\nfrom poutyne import torch_to_numpy\nfrom torchvision.utils import make_grid\n\ntorch.manual_seed(42)\nnp.random.seed(42)"}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "# Hyperparam\u00e8tres d'entra\u00eenement\ncuda_device = 0\ndevice = torch.device(\"cuda:%d\" % cuda_device if torch.cuda.is_available() else \"cpu\")\nbatch_size = 32\nlearning_rate = 0.01\nn_epoch = 5\nnum_classes = 10"}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "def load_cifar10(download=False, path='./', transform=None):\n    \"\"\"Loads the cifar10 dataset.\n\n    :param download: Download the dataset\n    :param path: Folder to put the dataset\n    :return: The train and test dataset\n    \"\"\"\n    train_dataset = CIFAR10(path, train=True, download=download, transform=transform)\n    test_dataset = CIFAR10(path, train=False, download=download, transform=transform)\n    return train_dataset, test_dataset\n\n\ndef load_cifar10_with_validation_set(download=False, path='./', train_split=0.8):\n    \"\"\"Loads the CIFAR10 dataset.\n\n    :param download: Download the dataset\n    :param path: Folder to put the dataset\n    :return: The train, valid and test dataset ready to be ingest in a neural network\n    \"\"\"\n    norm_coefs = {}\n    norm_coefs['imagenet'] = [(0.485, 0.456, 0.406), (0.229, 0.224, 0.225)]\n    transform = transforms.Compose([\n        transforms.Resize((224,224)),\n        transforms.ToTensor(),\n        transforms.Normalize(*norm_coefs['imagenet'])\n    ])\n    train, test = load_cifar10(download, path, transform=transform)\n    lengths = [round(train_split*len(train)), round((1.0-train_split)*len(train))]\n    train, valid = random_split(train, lengths)\n    return train, valid, test\n\ndef show_cifar10_examples(download=False, path='./'):\n    train, _ = load_cifar10(download, path)\n    num_lines = 3\n    plt.figure(figsize=(20,20*num_lines/3))\n    for i in range(num_lines*3):\n        plt.subplot(num_lines, 3, i + 1)\n        plt.imshow(train[i][0])\n        plt.title('\u00c9tiquette: %d' % train[i][1])\n    plt.show()\n\ndef count_number_of_parameters(net):\n    return sum(p.numel() for p in net.parameters() if p.requires_grad)"}, {"cell_type": "markdown", "metadata": {"editable": false}, "source": "Regardons quelques exemples d'images du jeu de donn\u00e9es. L'\u00e9tiquette indiqu\u00e9 au dessus de chaque image correspond au num\u00e9ro qui est attribu\u00e9 \u00e0 la classe de l'objet."}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "scrolled": false, "trusted": true}, "outputs": [], "source": "show_cifar10_examples(download=True)"}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "train, valid, test = load_cifar10_with_validation_set(download=True)"}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "len(train), len(valid), len(test)"}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\nvalid_loader = DataLoader(valid, batch_size=batch_size)\ntest_loader = DataLoader(test, batch_size=batch_size)"}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "def train(name, network, params=None):\n    print(network)\n    if not params:\n        params = network.parameters()\n\n    optimizer = optim.SGD(params, lr=learning_rate)\n    loss_function = nn.CrossEntropyLoss()\n    \n    early_stopping = EarlyStopping(patience=5, verbose=True)\n    lr_scheduler = ReduceLROnPlateau(patience=2, verbose=True)\n    callbacks = [early_stopping, lr_scheduler]\n\n    # Objet Model de Poutyne\n    model = Model(network, optimizer, loss_function, batch_metrics=['accuracy'])\n\n    # Envoie du mod\u00e8le sur GPU\n    model.to(device)\n\n    # Lancement de l'entra\u00eenement\n    model.fit_generator(train_loader, valid_loader, epochs=n_epoch, callbacks=callbacks)\n    return model"}, {"cell_type": "markdown", "metadata": {"editable": false}, "source": "Le code suivant impl\u00e9mente de mani\u00e8re orient\u00e9 objet le r\u00e9seau \u00e0 convolution r\u00e9sum\u00e9 dans le tableau ci-dessous. En commentaire dans le code, nous avons mis les dimensions du tenseur `x` \u00e0 chaque \u00e9tat du r\u00e9seau. Remarquez que ce r\u00e9seau a beaucoup plus de composantes que ceux des tutoriels pr\u00e9c\u00e9dents.\n\n| Type de couche                                     | Taille en sortie |     # de param\u00e8tres     |\n|------------------------------------------------|:-----------:|:-----------------------:|\n| Input                                          |   3x224x224   |            0            |\n| **Conv avec 10 filtres 3x3 avec padding de 1** |   10x224x224  |      10\\*3\\*3\\*3 +10 = 280     |\n| **BatchNorm avec transformation affine**       |   10x224x224  |      10 + 10 = 20     |\n| ReLU                                           |   10x224x224  |            0            |\n| MaxPool 2x2                                    |   10x112x112  |            0            |\n| **Conv avec 50 filtres 3x3 avec padding de 1** |   50x112x112  |      50\\*10\\*3\\*3 + 50 = 4 550     |\n| **BatchNorm avec transformation affine**       |   50x112x112  |      50 + 50 = 100     |\n| ReLU                                           |   50x112x112  |            0            |\n| MaxPool 2x2                                    |   50x56x56  |            0            |\n| **Conv avec 150 filtres 3x3 avec padding de 1** |  150x56x56  |      150\\*50\\*3\\*3 + 150 = 67 650     |\n| **BatchNorm avec transformation affine**       |   150x56x56  |      150 + 150 = 300     |\n| ReLU                                           |   150x56x56  |            0            |\n| Flatten                                        |   150\\*56\\*56  |            0            |\n| **Linear avec 10 neurons**                     |      10     |      150\\*56\\*56\\*10 + 10 = 4 704 010     |\n\n\\# total de param\u00e8tres: 4 776 910"}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "class CifarNet(nn.Module):\n    def __init__(self):\n        super(CifarNet, self).__init__()\n        \n        self.conv1 = nn.Conv2d(3, 10, 3, padding=1)\n        self.conv2 = nn.Conv2d(10, 50, 3, padding=1)\n        self.conv3 = nn.Conv2d(50, 150, 3, padding=1)\n        \n        self.batchnorm1 = nn.BatchNorm2d(10)\n        self.batchnorm2 = nn.BatchNorm2d(50)\n        self.batchnorm3 = nn.BatchNorm2d(150)\n        \n        self.fc1 = nn.Linear(150 * 56 * 56, num_classes)\n\n    def forward(self, x):\n        # x shape: (batch_size, 3, 224, 224)\n        x = F.max_pool2d(F.relu(self.batchnorm1(self.conv1(x))), (2, 2))\n        # x shape: (batch_size, 10, 112, 112)\n        x = F.max_pool2d(F.relu(self.batchnorm2(self.conv2(x))), (2, 2))\n        # x shape: (batch_size, 50, 56, 56)\n        x = F.relu(self.batchnorm3(self.conv3(x)))\n        # x shape: (batch_size, 150, 56, 56)\n        x = x.view(x.shape[0], -1)\n        # x shape: (batch_size, 470400)\n        x = self.fc1(x)\n        return x\n"}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "net = CifarNet()\nmodel = train('simple_cnn', net)"}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "model.evaluate_generator(test_loader)"}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "count_number_of_parameters(net)"}, {"cell_type": "markdown", "metadata": {"editable": false}, "source": "Comme vous l'avez peut-\u00eatre devin\u00e9, il est possible d'impl\u00e9menter le r\u00e9seau pr\u00e9c\u00e9dent en utilisant la m\u00e9thode s\u00e9quentiel de PyTorch tel que montr\u00e9 dans le Tutoriel 2. Votre t\u00e2che est donc de faire cette impl\u00e9mentation. Un d\u00e9but de code vous est fourni. Le tableau ci-dessous est une r\u00e9p\u00e9tition du tableau pr\u00e9c\u00e9dent.\n\n| Type de couche                                     | Taille en sortie |     # de param\u00e8tres     |\n|------------------------------------------------|:-----------:|:-----------------------:|\n| Input                                          |   3x224x224   |            0            |\n| **Conv avec 10 filtres 3x3 avec padding de 1** |   10x224x224  |      10\\*3\\*3\\*3 +10 = 280     |\n| **BatchNorm avec transformation affine**       |   10x224x224  |      10 + 10 = 20     |\n| ReLU                                           |   10x224x224  |            0            |\n| MaxPool 2x2                                    |   10x112x112  |            0            |\n| **Conv avec 50 filtres 3x3 avec padding de 1** |   50x112x112  |      50\\*10\\*3\\*3 + 50 = 4 550     |\n| **BatchNorm avec transformation affine**       |   50x112x112  |      50 + 50 = 100     |\n| ReLU                                           |   50x112x112  |            0            |\n| MaxPool 2x2                                    |   50x56x56  |            0            |\n| **Conv avec 150 filtres 3x3 avec padding de 1** |  150x56x56  |      150\\*50\\*3\\*3 + 150 = 67 650     |\n| **BatchNorm avec transformation affine**       |   150x56x56  |      150 + 150 = 300     |\n| ReLU                                           |   150x56x56  |            0            |\n| Flatten                                        |   150\\*56\\*56  |            0            |\n| **Linear avec 10 neurons**                     |      10     |      150\\*56\\*56\\*10 + 10 = 4 704 010     |\n\n\\# total de param\u00e8tres: 4 776 910"}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "net = nn.Sequential(\n    nn.Conv2d(3, 10, 3, padding=1),\n    nn.BatchNorm2d(10),\n    nn.ReLU(),\n    nn.MaxPool2d(2),\n    ... # \u00c0 faire: compl\u00e9ter le r\u00e9seau selon le tableau ci-dessus.\n)"}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "model = train('simple_sequential_cnn', net)"}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "model.evaluate_generator(test_loader)"}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "trusted": true}, "outputs": [], "source": "count_number_of_parameters(net)"}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "deletable": false, "id": "-4oZQu24WPIv", "trusted": true}, "outputs": [], "source": ""}], "metadata": {"PAX": {"revision": 928, "userLang": "fr"}, "accelerator": "GPU", "celltoolbar": "", "colab": {"collapsed_sections": [], "name": "Tutoriel 1.ipynb", "provenance": [], "version": "0.3.2"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.6"}, "revision": 928}, "nbformat": 4, "nbformat_minor": 1}