{"cells": [{"cell_type": "markdown", "metadata": {"colab_type": "text", "editable": false, "id": "CDEWTP-vNB_R"}, "source": "---\n# Pr\u00e9paration des Donn\u00e9es\n\n---\n\nPour pr\u00e9parer ad\u00e9quatement les donn\u00e9es avant de les fournir \u00e0 un ou plusieurs algorithmes d'apprentissage automatique, il faut \u00e9galement s'assurer de la bonne repr\u00e9sentation de ces donn\u00e9es pour ne pas leur fournir de biais trop difficiles \u00e0 manipuler.\n\n<center><img src=\"https://python.gel.ulaval.ca/media/sio-u009/mlprocess_2.png\" alt=\"Processus d'apprentissage automatique\" width=\"50%\"/></center>\n\n1. Le nettoyage et les aberrations statistiques\n2. L'imputation de donn\u00e9es manquantes\n3. **\u00c9quilibrage de donn\u00e9es d\u00e9s\u00e9quilibr\u00e9es**\n4. Transformation des caract\u00e9ristiques\n    1. *rescaling* et *normalizing* (\\[0, 1\\] ou \\[-1, 1\\]), *standardizing* (loi normale)\n    2. Repr\u00e9sentation matricielle de donn\u00e9es cat\u00e9goris\u00e9es\n    3. R\u00e9duction de la dimensionnalit\u00e9 ou cr\u00e9ation de caract\u00e9ristiques\n\n"}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "editable": false, "id": "-kcHEFbLJYGL"}, "source": "## 3. Donn\u00e9es d'entra\u00eenement d\u00e9s\u00e9quilibr\u00e9es\n\n### Paradoxe de l'Exactitude\n\nLe [paradoxe de l'exactitude](https://en.wikipedia.org/wiki/Accuracy_paradox) est le nom de la situation o\u00f9 vos mesures d'exactitude indiquent que vous avez une excellente exactitude (telle que 90%), mais que l'exactitude ne refl\u00e8te que la distribution de classe majoritaire sous-jacente.\n\nC'est un probl\u00e8me tr\u00e8s courant, car l'exactitude est souvent la premi\u00e8re mesure que utilis\u00e9e (par `scikit-learn`) pour \u00e9valuer les mod\u00e8les de nos probl\u00e8mes de classification.\n\n### Mettez tout sur le rouge!\n\nQue se passe-t-il dans les mod\u00e8les lorsque l'entrainement est fait sur un jeu de donn\u00e9es d\u00e9s\u00e9quilibr\u00e9? \n\nSi une exactitude de 90% est obtenue sur des donn\u00e9es d\u00e9s\u00e9quilibr\u00e9es (avec 90% des instances de la classe 1), c'est parce que les mod\u00e8les examinent les donn\u00e9es et d\u00e9cident intelligemment que la meilleure chose \u00e0 faire est de toujours pr\u00e9dire \"Classe 1\" et atteindre une grande exactitude.\n\nCela se voit mieux lorsque un algorithme bas\u00e9 sur des r\u00e8gles simples est utilis\u00e9. En regardant la r\u00e8gle dans le mod\u00e8le final, on constate qu'il est tr\u00e8s probable qu'une seule classe est pr\u00e9dite, quelles que soient les donn\u00e9es \u00e0 pr\u00e9dire.\n\nComment r\u00e9gler ce probl\u00e8me ?\n\n#### Collecter plus de donn\u00e9es\n\nVous pensez peut-\u00eatre que c'est idiot, mais la collecte de plus de donn\u00e9es est presque toujours n\u00e9glig\u00e9e.\n\nPouvez-vous collecter plus de donn\u00e9es? Prenez une seconde et demandez-vous si vous \u00eates capable de collecter plus de donn\u00e9es sur votre probl\u00e8me.\n\nUn ensemble de donn\u00e9es plus volumineux pourrait exposer une perspective diff\u00e9rente et peut-\u00eatre plus \u00e9quilibr\u00e9e des classes.\n\nD'autres exemples de classes mineures peuvent \u00eatre utiles ult\u00e9rieurement lorsque nous examinons le r\u00e9\u00e9chantillonnage de votre jeu de donn\u00e9es.\n\n#### Changer de m\u00e9trique de performance\n\nL'exactitude n'est pas la m\u00e9trique \u00e0 utiliser lorsque vous travaillez avec un jeu de donn\u00e9es d\u00e9s\u00e9quilibr\u00e9. Nous avons vu que c'est trompeur.\n\nCertains indicateurs ont \u00e9t\u00e9 con\u00e7us pour vous raconter une histoire plus v\u00e9ridique lorsque vous travaillez avec des classes d\u00e9s\u00e9quilibr\u00e9es.\n\nVous verrez plus en d\u00e9tails au prochain bloc les diff\u00e9rentes mesures de performance:\n- Matrice de confusion: d\u00e9composition des pr\u00e9dictions dans un tableau montrant les pr\u00e9dictions correctes (la diagonale) et les types de pr\u00e9dictions incorrectes effectu\u00e9es (quelles classes de pr\u00e9dictions incorrectes ont \u00e9t\u00e9 attribu\u00e9es).\n- Exactitude: Mesure de l'exactitude d'un classificateur.\n- Rappel : Une mesure de la compl\u00e9tude d'un classificateur\n- Score F1 (ou F-score): moyenne pond\u00e9r\u00e9e de la pr\u00e9cision et du rappel.\n- Kappa (ou [kappa de Cohen](https://en.wikipedia.org/wiki/Cohen%27s_kappa)): pr\u00e9cision de la classification normalis\u00e9e par le d\u00e9s\u00e9quilibre des classes dans les donn\u00e9es.\n- Courbes ROC: \u00c0 l'instar de la pr\u00e9cision et du rappel, l'exactitude est divis\u00e9e en sensibilit\u00e9 et sp\u00e9cificit\u00e9 et des mod\u00e8les peuvent \u00eatre choisis en fonction des seuils d'\u00e9quilibre de ces valeurs.\n\nTout cela sera vu au prochain bloc sur l'\u00e9valuation de mod\u00e8les.\n\n#### R\u00e9-\u00e9chantillonner le jeu de donn\u00e9es\n\nIl est possible de modifier le jeu de donn\u00e9es utilis\u00e9 afin d'obtenir des donn\u00e9es plus \u00e9quilibr\u00e9es et am\u00e9liorer le mod\u00e8le pr\u00e9dictif.\n\nCette modification s'appelle [\u00e9chantillonnage du dataset](https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis). Il existe deux m\u00e9thodes principales pour uniformiser les classes:\n- l'ajout de copies d'instances de la classe sous-repr\u00e9sent\u00e9e : sur-\u00e9chantillonnage (ou plus formellement \u00e9chantillonner avec remplacement), ou\n- la suppression d'instances de la classe surrepr\u00e9sent\u00e9e : sous-\u00e9chantillonnage.\n\nCes approches sont souvent tr\u00e8s faciles \u00e0 mettre en \u0153uvre et rapides \u00e0 ex\u00e9cuter. Elles sont un excellent point de d\u00e9part.\n\nEn fait, il vaut mieux toujours essayer les deux approches sur tous les jeux de donn\u00e9es d\u00e9s\u00e9quilibr\u00e9s, juste pour voir si cela donne une am\u00e9lioration de vos mesures pr\u00e9f\u00e9r\u00e9es.\n\nQuelques r\u00e8gles de base :\n- Le sous-\u00e9chantillonnage est pr\u00e9f\u00e9rable lorsque vous avez beaucoup de donn\u00e9es (des dizaines, des centaines de milliers d'instances ou plus).\n- Le sur\u00e9chantillonnage est pr\u00e9f\u00e9rable lorsque vous n\u2019avez pas beaucoup de donn\u00e9es (des dizaines de milliers d\u2019enregistrements ou moins).\n- Tester des sch\u00e9mas d'\u00e9chantillonnage al\u00e9atoire et non al\u00e9atoire (par exemple stratifi\u00e9).\n- Tester diff\u00e9rents ratios de r\u00e9\u00e9chantillonnage (il n'est pas toujours n\u00e9cessaire d'avoir un ratio de 1:1 dans un probl\u00e8me de classification binaire).\n\n#### G\u00e9n\u00e9rer des \u00e9chantillons synth\u00e9tiques\n\nUn moyen simple de g\u00e9n\u00e9rer des \u00e9chantillons synth\u00e9tiques consiste \u00e0 \u00e9chantillonner de mani\u00e8re al\u00e9atoire les attributs d'instances de la classe minoritaire.\n\nIl est possible de les \u00e9chantillonner de mani\u00e8re empirique dans votre jeu de donn\u00e9es ou d'utiliser une m\u00e9thode telle que Naive Bayes, qui permet d'\u00e9chantillonner chaque attribut ind\u00e9pendamment lorsqu'il est ex\u00e9cut\u00e9 \u00e0 l'envers. Plus de donn\u00e9es diff\u00e9rentes seront g\u00e9n\u00e9r\u00e9es, mais les relations non-lin\u00e9aires entre les attributs peuvent ne pas \u00eatre pr\u00e9serv\u00e9es.\n\nIl existe des algorithmes syst\u00e9matiques utilisables pour g\u00e9n\u00e9rer des \u00e9chantillons synth\u00e9tiques. Le plus populaire de ces algorithmes est appel\u00e9 SMOTE ou technique de sur\u00e9chantillonnage minoritaire synth\u00e9tique.\n\nSMOTE est une m\u00e9thode de sur\u00e9chantillonnage. Cela fonctionne en cr\u00e9ant des \u00e9chantillons synth\u00e9tiques de la classe mineure au lieu de cr\u00e9er des copies. L'algorithme s\u00e9lectionne deux instances similaires ou plus (\u00e0 l'aide d'une mesure de distance) et perturbe une instance \u00e0 la fois d'une quantit\u00e9 al\u00e9atoire dans la diff\u00e9rence des instances voisines.\n\nIl existe plusieurs impl\u00e9mentations de l'algorithme SMOTE. En Python, le module \"[`imbalanced-learn`](https://github.com/fmfn/UnbalancedDataset)\" fournit un certain nombre d'impl\u00e9mentations de SMOTE ainsi que diverses autres techniques de r\u00e9-\u00e9chantillonnage.\n\n#### Essayer les mod\u00e8les p\u00e9nalis\u00e9s\n\nUtilisation des m\u00eames algorithmes habituels en leur donnant une perspective diff\u00e9rente du probl\u00e8me.\n\nLa classification p\u00e9nalis\u00e9e impose un co\u00fbt suppl\u00e9mentaire au mod\u00e8le pour faire des erreurs de classification \u00e0 la classe minoritaire pendant l'entrainement. Ces p\u00e9nalit\u00e9s peuvent inciter le mod\u00e8le \u00e0 accorder plus d\u2019attention \u00e0 la classe minoritaire.\n\nSouvent, le traitement des p\u00e9nalit\u00e9s de classe ou des poids est sp\u00e9cialis\u00e9 dans l\u2019algorithme d\u2019apprentissage. Il existe des versions p\u00e9nalis\u00e9es d'algorithmes tels que les SVMs ou LDAs.\n\nIl est \u00e9galement possible d'avoir des cadres g\u00e9n\u00e9riques pour les mod\u00e8les p\u00e9nalis\u00e9s. Par exemple, Weka a un classificateur CostSensitive qui peut envelopper tout classificateur et appliquer une matrice de p\u00e9nalit\u00e9s personnalis\u00e9e pour la classification des \u00e9checs.\n\nL\u2019utilisation de la p\u00e9nalisation est souhaitable si vous \u00eates bloqu\u00e9 dans un algorithme sp\u00e9cifique et \u00eates incapable de r\u00e9\u00e9chantillonner ou si vous obtenez des r\u00e9sultats m\u00e9diocres. Il fournit un autre moyen d\u2019\u00e9quilibrer les cours. La mise en place de la matrice de p\u00e9nalit\u00e9s peut \u00eatre complexe. Vous devrez tr\u00e8s probablement essayer divers syst\u00e8mes de p\u00e9nalit\u00e9s et voir ce qui convient le mieux \u00e0 votre probl\u00e8me.\n\n#### Essayer une perspective diff\u00e9rente\n\nIl existe des domaines d'\u00e9tude d\u00e9di\u00e9s aux jeux de donn\u00e9es d\u00e9s\u00e9quilibr\u00e9s. Ils ont leurs propres algorithmes, mesures et terminologie.\n\nJeter un coup d'\u0153il et r\u00e9fl\u00e9chir \u00e0 votre probl\u00e8me sous ces angles peut parfois faire honte \u00e0 certaines id\u00e9es.\n\nLa d\u00e9tection des anomalies et la d\u00e9tection des modifications sont deux \u00e9l\u00e9ments qui pourraient vous int\u00e9resser.\n\nLa d\u00e9tection d'anomalie est la d\u00e9tection d'\u00e9v\u00e9nements rares. Il s\u2019agit peut-\u00eatre d\u2019un dysfonctionnement de la machine signal\u00e9 par ses vibrations ou d\u2019une activit\u00e9 malveillante d\u2019un programme indiqu\u00e9 par sa s\u00e9quence d\u2019appels syst\u00e8me. Les \u00e9v\u00e9nements sont rares et compar\u00e9s au fonctionnement normal.\n\nCe changement de mentalit\u00e9 consid\u00e8re la classe mineure comme la classe des valeurs aberrantes, ce qui peut vous aider \u00e0 r\u00e9fl\u00e9chir \u00e0 de nouvelles fa\u00e7ons de s\u00e9parer et de classer les \u00e9chantillons.\n\nLa d\u00e9tection de changement est similaire \u00e0 la d\u00e9tection d'anomalie, sauf que plut\u00f4t que de rechercher une anomalie, elle recherche un changement ou une diff\u00e9rence. Il peut s\u2019agir d\u2019un changement de comportement d\u2019un utilisateur, tel qu\u2019observ\u00e9 par les mod\u00e8les d\u2019utilisation ou les transactions bancaires.\n\nCes deux \u00e9volutions adoptent une approche plus en temps r\u00e9el du probl\u00e8me de classification qui pourrait vous donner de nouvelles fa\u00e7ons de penser \u00e0 votre probl\u00e8me et peut-\u00eatre d\u2019autres techniques \u00e0 essayer."}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "editable": false, "id": "unIwB9grJYGL"}, "source": "### Exemple de donn\u00e9es d\u00e9balanc\u00e9es\n\n* Jeu de donn\u00e9es d\u00e9balanc\u00e9\n* Le pi\u00e8ge m\u00e9trique\n* Matrice de confusion\n* R\u00e9\u00e9chantillonnage\n* Sous-\u00e9chantillonnage al\u00e9atoire\n* Sur\u00e9chantillonnage al\u00e9atoire\n* Module d'apprentissage en Python d\u00e9s\u00e9quilibr\u00e9\n* Sous-\u00e9chantillonnage al\u00e9atoire et sur-\u00e9chantillonnage avec apprentissage d\u00e9s\u00e9quilibr\u00e9\n* Sous-\u00e9chantillonnage: liens Tomek\n* Sous-\u00e9chantillonnage: Centroids de cluster\n* Sur\u00e9chantillonnage: SMOTE\n* Sur-\u00e9chantillonnage suivi d'un sous-\u00e9chantillonnage\n* Plus de liens"}, {"cell_type": "markdown", "metadata": {"_cell_guid": "e38ddf38-d027-4eae-95c8-749f8f40db43", "_uuid": "1e287038acf96fc6d6825e77ba97b03f0824be0a", "colab_type": "text", "editable": false, "id": "4P9xKvrdJYGL"}, "source": "#### Donn\u00e9es d\u00e9balanc\u00e9es\n\nDans cette partie, nous passons en revue certaines techniques permettant de g\u00e9rer des ensembles de donn\u00e9es tr\u00e8s d\u00e9balanc\u00e9es, en mettant l\u2019accent sur le r\u00e9-\u00e9chantillonnage. "}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "deletable": false, "id": "5aWXfX8bJYGL", "trusted": true}, "outputs": [], "source": "import numpy as np\nimport pandas as pd\n\nfrom sklearn.datasets import make_classification\n\nmajor = 0.99\n\nX, y = make_classification(\n    n_classes=2, class_sep=1.5, weights=[major, 1-major],\n    n_informative=3, n_redundant=1, flip_y=0,\n    n_features=20, n_clusters_per_class=1,\n    n_samples=100000, random_state=10\n)\n\ndf = pd.DataFrame(X)\ndf['target'] = y\ntarget_count = df.target.value_counts()\nprint('Class 0:', target_count[0])\nprint('Class 1:', target_count[1])\nprint('Proportion:', round(target_count[0] / target_count[1], 4), ': 1')\ndf.target.value_counts().plot(kind='bar', title='Count (target)');"}, {"cell_type": "markdown", "metadata": {"_cell_guid": "c91f9c5d-05d2-478e-9dfb-1cb848bc0fe4", "_uuid": "8683656d1bfdef6b5c0c623597dcbc4160a0edc1", "colab_type": "text", "editable": false, "id": "-vMLdhPcJYGN"}, "source": "#### Le pi\u00e8ge des m\u00e9triques\n\nL'un des principaux probl\u00e8mes auxquels se heurtent les utilisateurs novices lorsqu'ils traitent des ensembles de donn\u00e9es non \u00e9quilibr\u00e9s est li\u00e9 aux m\u00e9triques utilis\u00e9es pour \u00e9valuer leur mod\u00e8le. Utiliser des m\u00e9triques plus simples comme l'exactitude (`accuracy`) peut \u00eatre trompeur. Dans un ensemble de donn\u00e9es avec des classes tr\u00e8s d\u00e9s\u00e9quilibr\u00e9es, si le classificateur \"pr\u00e9dit\" toujours la classe la plus courante sans effectuer d'analyse des caract\u00e9ristiques, il conservera un taux de pr\u00e9cision \u00e9lev\u00e9, \u00e9videmment illusoire.\n\nFaisons cette exp\u00e9rience en utilisant une simple validation crois\u00e9e et aucune ing\u00e9nierie de caract\u00e9ristiques:"}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "deletable": false, "id": "MX43hWb3JYGN", "trusted": true}, "outputs": [], "source": "from sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n\nmodel = XGBClassifier()\nmodel = SVC(kernel='linear')\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy: %.4f%%\" % (accuracy * 100.0))"}, {"cell_type": "markdown", "metadata": {"_cell_guid": "c46b98a7-d500-4911-a7b5-c8fc8fbed069", "_uuid": "5b17ee8d3629cc346398e63269205e5b654cef80", "colab_type": "text", "editable": false, "id": "UovfJF0vJYGN"}, "source": "Ex\u00e9cutons maintenant le m\u00eame code, mais en utilisant une seule caract\u00e9ristique (ce qui devrait consid\u00e9rablement r\u00e9duire l'exactitude du classificateur):"}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "deletable": false, "id": "RA8ch-k0JYGN", "trusted": true}, "outputs": [], "source": "model = XGBClassifier()\nmodel = SVC(kernel='linear')\nmodel.fit(X_train[:,0:2], y_train)\ny_pred = model.predict(X_test[:,0:2])\n\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy: %.4f%%\" % (accuracy * 100.0))"}, {"cell_type": "markdown", "metadata": {"_cell_guid": "68d4ffaf-4412-4ff3-a9cd-38bea195da3b", "_uuid": "d9d8b57f458bdd107ae08b76b0008d80e0674d97", "colab_type": "text", "editable": false, "id": "U6ycFBWPJYGO"}, "source": "Comme nous pouvons le constater, le taux de pr\u00e9cision \u00e9lev\u00e9 n\u2019\u00e9tait qu\u2019une illusion. De cette mani\u00e8re, le choix de la m\u00e9trique utilis\u00e9e dans les jeux de donn\u00e9es non \u00e9quilibr\u00e9s est extr\u00eamement important. Dans cette comp\u00e9tition, la m\u00e9trique d'\u00e9valuation \u00e9tait le [Coefficient de Gini normalis\u00e9](https://en.wikipedia.org/wiki/Gini_coefficient), une m\u00e9trique plus robuste pour les jeux de donn\u00e9es d\u00e9s\u00e9quilibr\u00e9s, qui varie d'environ 0 pour une estimation al\u00e9atoire \u00e0 environ 0,5 pour un score parfait."}, {"cell_type": "markdown", "metadata": {"_cell_guid": "e53e9f0f-8888-4fd9-b0d8-3bc937448162", "_uuid": "a176bd80315afd0f7c21fd26ab1841867a5eb7d0", "colab_type": "text", "editable": false, "id": "XLwQK0ztJYGP"}, "source": "#### Matrice de Confusion\n\nUne m\u00e9thode int\u00e9ressante pour \u00e9valuer les r\u00e9sultats consiste \u00e0 utiliser une matrice de confusion qui montre les pr\u00e9dictions correctes et incorrectes pour chaque classe. Dans la premi\u00e8re ligne, la premi\u00e8re colonne indique combien de classes 0 ont \u00e9t\u00e9 pr\u00e9dites correctement, et dans la seconde colonne, combien de classes 0 ont \u00e9t\u00e9 pr\u00e9dites \u00e0 1. Dans la deuxi\u00e8me ligne, nous notons que toutes les entr\u00e9es de classe 1 ont \u00e9t\u00e9 pr\u00e9dites \u00e0 tort comme \u00e9tant la classe 0.\n\nPar cons\u00e9quent, plus les valeurs diagonales de la matrice de confusion sont \u00e9lev\u00e9es, mieux ce sera, ce qui indique de nombreuses pr\u00e9dictions correctes."}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "deletable": false, "id": "lT2XS_k2JYGP", "trusted": true}, "outputs": [], "source": "from sklearn.metrics import confusion_matrix\nfrom matplotlib import pyplot as plt\n\nconf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\nprint('Matrice de confusion:\\n', conf_mat)\n\nlabels = ['Class 0', 'Class 1']\nfig = plt.figure()\nax = fig.add_subplot(111)\ncax = ax.matshow(conf_mat, cmap=plt.cm.jet_r)\nfig.colorbar(cax)\nax.set_xticklabels([''] + labels)\nax.set_yticklabels([''] + labels)\nplt.xlabel('Predicted')\nplt.ylabel('Expected')\nplt.show()"}, {"cell_type": "markdown", "metadata": {"_cell_guid": "b27346eb-7bf3-4360-993a-fb91e62bb937", "_uuid": "875f5ab3b5afcdaf3c7754ce957cb01fd32bf65c", "colab_type": "text", "editable": false, "id": "nNvxT6KxJYGQ"}, "source": "#### R\u00e9\u00e9chantillonage\n\nLe r\u00e9\u00e9chantillonnage est une technique largement adopt\u00e9e pour traiter les jeux de donn\u00e9es tr\u00e8s d\u00e9s\u00e9quilibr\u00e9s. Cela consiste \u00e0 retirer des \u00e9chantillons de la classe majoritaire (sous-\u00e9chantillonnage) et / ou \u00e0 ajouter d'autres exemples de la classe minoritaire (sur-\u00e9chantillonnage)."}, {"cell_type": "markdown", "metadata": {"_cell_guid": "03d31a16-7b66-4096-88d7-d548db734390", "_uuid": "2232ac0fb192a468486b400846f88913a36957e6", "colab_type": "text", "editable": false, "id": "ebU83Co8JYGQ"}, "source": "![](https://raw.githubusercontent.com/rafjaa/machine_learning_fecib/master/src/static/img/resampling.png)"}, {"cell_type": "markdown", "metadata": {"_cell_guid": "0df1a3f3-49ff-4ada-80f1-198bbbd79525", "_uuid": "67e203e0919c818e871650ef194fe497df2d39b5", "colab_type": "text", "editable": false, "id": "1BoXNnQjJYGQ"}, "source": "Malgr\u00e9 l'avantage de l'\u00e9quilibrage des classes, ces techniques ont aussi leurs faiblesses (`No Free Lunch`). La mise en \u0153uvre la plus simple du sur\u00e9chantillonnage consiste \u00e0 dupliquer al\u00e9atoirement des donn\u00e9es  de la classe de minorit\u00e9, ce qui peut entra\u00eener une sur-apprentissage. Dans le sous-\u00e9chantillonnage, la technique la plus simple consiste \u00e0 supprimer al\u00e9atoirement des enregistrements de la classe majoritaire, ce qui peut entra\u00eener une perte d'information.\n\nImpl\u00e9mentons un exemple de base, qui utilise la m\u00e9thode `DataFrame.sample` pour obtenir al\u00e9atoirement des \u00e9chantillons de chaque classe:"}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "deletable": false, "id": "v6PAuyH6JYGR", "trusted": true}, "outputs": [], "source": "# Nombre de valeurs par classe\ncount_class_0, count_class_1 = df.target.value_counts()\n\n# S\u00e9paration des classes\ndf_class_0 = df[df['target'] == 0]\ndf_class_1 = df[df['target'] == 1]"}, {"cell_type": "markdown", "metadata": {"_cell_guid": "152ea73a-aa23-4fd2-a3f5-1f55c69041ae", "_uuid": "b765be76a182930feb650b01dd4d1de90501bbce", "colab_type": "text", "editable": false, "id": "VHf9W_hkJYGR"}, "source": "#### Sous-\u00e9chantillonnage al\u00e9atoire"}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "deletable": false, "id": "HSfmgXlqJYGS", "trusted": true}, "outputs": [], "source": "df_class_0_under = df_class_0.sample(count_class_1)\ndf_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n\nprint('Sous-\u00e9chantillonnage al\u00e9atoire:')\nprint(df_test_under.target.value_counts())\n\ndf_test_under.target.value_counts().plot(kind='bar', title='Count (target)');"}, {"cell_type": "markdown", "metadata": {"_cell_guid": "be656d47-e529-4533-b975-cf6de072d959", "_uuid": "17192fe8557463941e3abd4633b58ced0037721b", "colab_type": "text", "editable": false, "id": "MNTDbt6UJYGS"}, "source": "#### Sur\u00e9chantillonnage al\u00e9atoire"}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "deletable": false, "id": "1LSXyrUuJYGS", "trusted": true}, "outputs": [], "source": "df_class_1_over = df_class_1.sample(count_class_0, replace=True)\ndf_test_over = pd.concat([df_class_0, df_class_1_over], axis=0)\n\nprint('Sur\u00e9chantillonnage al\u00e9atoire:')\nprint(df_test_over.target.value_counts())\n\ndf_test_over.target.value_counts().plot(kind='bar', title='Count (target)');"}, {"cell_type": "markdown", "metadata": {"_cell_guid": "9fd90ddc-f2fc-487d-b177-0c540daf2eff", "_uuid": "9672899d4029b71b72897927ce464d6d7427ce77", "colab_type": "text", "editable": false, "id": "wvatSDl0JYGU"}, "source": "#### Module d'apprentissage en Python d\u00e9s\u00e9quilibr\u00e9\n\nUn certain nombre de techniques de r\u00e9-\u00e9chantillonnage plus sophistiqu\u00e9es ont \u00e9t\u00e9 propos\u00e9es dans la litt\u00e9rature scientifique.\n\nPar exemple, il est possible de regrouper les donn\u00e9es de la classe majoritaire et d'effectuer le sous-\u00e9chantillonnage en supprimant les donn\u00e9es de chaque cluster, cherchant ainsi \u00e0 pr\u00e9server les informations. En sur-\u00e9chantillonnage, au lieu de cr\u00e9er des copies exactes des donn\u00e9es de la classe de minorit\u00e9, nous pouvons introduire de petites variations dans ces copies, cr\u00e9ant ainsi des \u00e9chantillons synth\u00e9tiques plus divers.\n\nAppliquons certaines de ces techniques de r\u00e9\u00e9chantillonnage en utilisant la librairie Python [imbalanced-learn](http://contrib.scikit-learn.org/imbalanced-learn/stable/). Elle est compatible avec scikit-learn et fait partie des projets scikit-learn-contrib."}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "deletable": false, "id": "FClginO8JYGU", "trusted": true}, "outputs": [], "source": "#!pip install imblearn\nimport imblearn"}, {"cell_type": "markdown", "metadata": {"_cell_guid": "5542beb4-6aee-401a-8bc0-2a522fbbe90b", "_uuid": "ff93d1707c416178c010c125319220b785dca984", "colab_type": "text", "editable": false, "id": "_84pBL0WJYGV"}, "source": "Pour faciliter la visualisation, cr\u00e9ons un petit \u00e9chantillon de donn\u00e9es non \u00e9quilibr\u00e9 \u00e0 l'aide de la m\u00e9thode `make_classification`:"}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "deletable": false, "id": "NzSxdsYvJYGW", "trusted": true}, "outputs": [], "source": "from sklearn.datasets import make_classification\n\nX, y = make_classification(\n    n_classes=2, class_sep=1.5, weights=[0.9, 0.1],\n    n_informative=3, n_redundant=1, flip_y=0,\n    n_features=20, n_clusters_per_class=1,\n    n_samples=100, random_state=10\n)\n\ndf = pd.DataFrame(X)\ndf['target'] = y\ndf.target.value_counts().plot(kind='bar', title='Count (target)');"}, {"cell_type": "markdown", "metadata": {"_cell_guid": "4de57657-3aed-4444-a609-318063391763", "_uuid": "d348b114ec1594eeefa0a67aab8b54e5b9ee2bdf", "colab_type": "text", "editable": false, "id": "21MrHWhjJYGW"}, "source": "Nous allons \u00e9galement cr\u00e9er une fonction de trac\u00e9 \u00e0 2 dimensions, <code>plot_2d_space</code>, pour afficher la r\u00e9partition des donn\u00e9es:"}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "deletable": false, "id": "T9--S3muJYGX", "trusted": true}, "outputs": [], "source": "def plot_2d_space(X, y, label='Classes'):   \n    colors = ['#1F77B4', '#FF7F0E']\n    markers = ['o', 's']\n    for l, c, m in zip(np.unique(y), colors, markers):\n        plt.scatter(\n            X[y==l, 0],\n            X[y==l, 1],\n            c=c, label=l, marker=m,alpha=.5\n        )\n    plt.title(label)\n    plt.legend(loc='upper right')\n    plt.show()"}, {"cell_type": "markdown", "metadata": {"_cell_guid": "2c565bbc-39ed-45a2-8b3d-bc501e2510aa", "_uuid": "aabc110dd8d1b36345df6aada1c59b864e48e8e6", "colab_type": "text", "editable": false, "id": "7zGNtx2oJYGX"}, "source": "\u00c9tant donn\u00e9 que le jeu de donn\u00e9es comporte de nombreuses dimensions (caract\u00e9ristiques) et que nos graphiques seront en 2D, la taille du jeu de donn\u00e9es est r\u00e9duite par analyse en composantes principales (PCA):"}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "deletable": false, "id": "d1lDgQ4tJYGY", "trusted": true}, "outputs": [], "source": "from sklearn.decomposition import PCA\n\npca = PCA(n_components=2)\nX = pca.fit_transform(X)\n\nplot_2d_space(X, y, 'Imbalanced dataset (2 PCA components)')"}, {"cell_type": "markdown", "metadata": {"_cell_guid": "c3c9a24f-3cd0-4c8d-8a4d-4403c4f1a641", "_uuid": "0d7316b04837aa103003d667f63ecb05d43fc04e", "colab_type": "text", "editable": false, "id": "5S_xEobzJYGY"}, "source": "#### Sous-\u00e9chantillonnage al\u00e9atoire et sur-\u00e9chantillonnage avec apprentissage d\u00e9s\u00e9quilibr\u00e9"}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "deletable": false, "id": "7dwC1yZGJYGZ", "trusted": true}, "outputs": [], "source": "from imblearn.under_sampling import RandomUnderSampler\n\nrus = RandomUnderSampler()\nX_rus, y_rus = rus.fit_sample(X, y)\nid_rus = rus.sample_indices_\n\nprint('Indices retir\u00e9s :', id_rus)\n\nplot_2d_space(X_rus, y_rus, 'Sous-\u00e9chantillonnage al\u00e9atoire')"}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "deletable": false, "id": "qqLX1lZOJYGa", "trusted": true}, "outputs": [], "source": "from imblearn.over_sampling import RandomOverSampler\n\nros = RandomOverSampler()\nX_ros, y_ros = ros.fit_sample(X, y)\n\nprint(X_ros.shape[0] - X.shape[0], 'nouveaux points al\u00e9atoires')\n\nplot_2d_space(X_ros, y_ros, 'Sur-\u00e9chantillonnage al\u00e9atoire')"}, {"cell_type": "markdown", "metadata": {"_cell_guid": "3156134f-539b-48b8-b9d0-64095fe50c1c", "_uuid": "b3f9ac47a157d9096a626360408859b795299c24", "colab_type": "text", "editable": false, "id": "0ccg8RTMJYGb"}, "source": "#### Sous-\u00e9chantillonnage: liens Tomek\n\nLes liens Tomek sont des paires d'instances tr\u00e8s proches, mais de classes oppos\u00e9es. La suppression des occurrences de la classe majoritaire de chaque paire augmente l'espace entre les deux classes, facilitant ainsi le processus de classification."}, {"cell_type": "markdown", "metadata": {"_cell_guid": "f131f7e0-007d-406e-9e1c-db352d2d8433", "_uuid": "85c01c0e6baa1b984585c1db34c5ab0315cbf8ff", "colab_type": "text", "editable": false, "id": "TRr25kbSJYGc"}, "source": "![](https://raw.githubusercontent.com/rafjaa/machine_learning_fecib/master/src/static/img/tomek.png?v=2)"}, {"cell_type": "markdown", "metadata": {"_cell_guid": "45bf057b-369c-4f37-a5ac-7417ad79253d", "_uuid": "733a86ccfaaabf701fb2d1f9997c732b19630df3", "colab_type": "text", "editable": false, "id": "rZSenONRJYGc"}, "source": "Dans le code ci-dessous, nous utiliserons `sampling_strategy = 'majority'` pour r\u00e9\u00e9chantillonner la classe majoritaire."}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "deletable": false, "id": "ETV-o6A_JYGd", "trusted": true}, "outputs": [], "source": "from imblearn.under_sampling import TomekLinks\n\ntl = TomekLinks(sampling_strategy='majority')\nX_tl, y_tl = tl.fit_sample(X, y)\nid_tl = tl.sample_indices_\n\nprint('Indices retir\u00e9s:', id_tl)\n\nplot_2d_space(X_tl, y_tl, ' Sous-\u00e9chantillonnage des liens Tomek')"}, {"cell_type": "markdown", "metadata": {"_cell_guid": "fef831bd-ecec-429c-aef2-5d51d1188820", "_uuid": "b4e75fffe4c91afcd63705aa7bcb16b6fd9f6b1f", "colab_type": "text", "editable": false, "id": "kJJ1TDfQJYGd"}, "source": "#### Sous-\u00e9chantillonnage: Centroids de cluster\n\nCette technique effectue un sous-\u00e9chantillonnage en g\u00e9n\u00e9rant des centro\u00efdes bas\u00e9s sur des m\u00e9thodes de clustering. Les donn\u00e9es seront pr\u00e9alablement regroup\u00e9es par similarit\u00e9, afin de pr\u00e9server les informations.\n\nDans cet exemple, le dictionnaire `{0: 10}` pour le param\u00e8tre `sampling_strategy`, indique de pr\u00e9server 10 \u00e9l\u00e9ments de la classe majoritaire (0) et conserver toutes les donn\u00e9es de la classe minoritaire (1)."}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "deletable": false, "id": "IOqxw1v-JYGe", "trusted": true}, "outputs": [], "source": "from imblearn.under_sampling import ClusterCentroids\n\ncc = ClusterCentroids(sampling_strategy={0: 10})\nX_cc, y_cc = cc.fit_sample(X, y)\n\nplot_2d_space(X_cc, y_cc, 'Cluster Centroids under-sampling')"}, {"cell_type": "markdown", "metadata": {"_cell_guid": "78adb7b4-a7e1-4d10-9cc2-6bf6477c63df", "_uuid": "b3741f5c14acdbd76e25725e2d73df5f2cb0a239", "colab_type": "text", "editable": false, "id": "D253k0hKJYGf"}, "source": "#### Sur\u00e9chantillonnage: SMOTE\n\nSMOTE (Synthetic Minority Oversampling TEchnique) consiste \u00e0 synth\u00e9tiser des \u00e9l\u00e9ments pour la classe minoritaire, sur la base de ceux qui existent d\u00e9j\u00e0. Cela fonctionne de mani\u00e8re al\u00e9atoire en s\u00e9lectionnant un point de la classe minoritaire et en calculant les k-voisins les plus proches pour ce point (k-NN). Les points synth\u00e9tiques sont ajout\u00e9s entre le point choisi et ses voisins."}, {"cell_type": "markdown", "metadata": {"_cell_guid": "5162646f-da82-4877-b6d8-25a8be7f42e9", "_uuid": "51697e21b7cdb4064dda18aa24e6ecf039b1132b", "colab_type": "text", "editable": false, "id": "B_4tNNw_JYGf"}, "source": " ![](https://raw.githubusercontent.com/rafjaa/machine_learning_fecib/master/src/static/img/smote.png)"}, {"cell_type": "markdown", "metadata": {"_cell_guid": "9c0a0d78-8427-437e-aa24-ffe2bd12edb2", "_uuid": "9393851db694c178faf93615bf05addedf5d678b", "colab_type": "text", "editable": false, "id": "bpagjV0qJYGf"}, "source": "Nous allons utiliser `sampling_strategy = 'minority'` pour r\u00e9\u00e9chantillonner la classe de minorit\u00e9."}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "deletable": false, "id": "F1QtSQAZJYGg", "trusted": true}, "outputs": [], "source": "from imblearn.over_sampling import SMOTE\n\nsmote = SMOTE(sampling_strategy='minority')\nX_sm, y_sm = smote.fit_sample(X, y)\n\nplot_2d_space(X_sm, y_sm, 'SMOTE over-sampling')"}, {"cell_type": "markdown", "metadata": {"_cell_guid": "20c3cdbb-a7c1-45a5-8dd9-84cff7d9af31", "_uuid": "d7ebbeb741ad6469cb7ebbced3499acd3c49856a", "colab_type": "text", "editable": false, "id": "Pcf-01CvJYGh"}, "source": "#### Sur-\u00e9chantillonnage suivi d'un sous-\u00e9chantillonnage\n\nNous pouvons maintenant combiner le sur\u00e9chantillonnage et le sur\u00e9chantillonnage, en utilisant les techniques des liens SMOTE et Tomek:"}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "deletable": false, "id": "xb2sJvsdJYGh", "trusted": true}, "outputs": [], "source": "from imblearn.combine import SMOTETomek\n\nsmt = SMOTETomek(sampling_strategy='auto')\nX_smt, y_smt = smt.fit_sample(X, y)\n\nplot_2d_space(X_smt, y_smt, 'SMOTE + Tomek links')"}, {"cell_type": "markdown", "metadata": {"_cell_guid": "28d4431f-bc32-4cf0-988e-9df412cc22c1", "_uuid": "401bcb8e508e584feca3a34ecfb9de270fde951c", "colab_type": "text", "editable": false, "id": "9BhXXaOoJYGi"}, "source": "#### Plus de liens\n\n* Documentation imbalanced-learn :<br>\nhttp://contrib.scikit-learn.org/imbalanced-learn/stable/index.html\n* GitHub imbalanced-learn :<br>\nhttps://github.com/scikit-learn-contrib/imbalanced-learn\n* Comparaison de la combinaison des algorithmes de sur- et sous-\u00e9chantillonnage:<br>\nhttp://contrib.scikit-learn.org/imbalanced-learn/stable/auto_examples/combine/plot_comparison_combine.html\n* Chawla, Nitesh V., et al. \"SMOTE: synthetic minority over-sampling technique.\" Journal of artificial intelligence research 16 (2002):<br>\nhttps://www.jair.org/media/953/live-953-2037-jair.pdf"}], "metadata": {"PAX": {"revision": 794, "userLang": "fr"}, "celltoolbar": "", "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.1"}, "revision": 794, "varInspector": {"cols": {"lenName": 16, "lenType": 16, "lenVar": 40}, "kernels_config": {"python": {"delete_cmd_postfix": "", "delete_cmd_prefix": "del ", "library": "var_list.py", "varRefreshCmd": "print(var_dic_list())"}, "r": {"delete_cmd_postfix": ") ", "delete_cmd_prefix": "rm(", "library": "var_list.r", "varRefreshCmd": "cat(var_dic_list()) "}}, "types_to_exclude": ["module", "function", "builtin_function_or_method", "instance", "_Feature"], "window_display": false}}, "nbformat": 4, "nbformat_minor": 1}